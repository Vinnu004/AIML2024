{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y32ZJbWtSPD4",
        "outputId": "37505042-8e0e-4345-cd09-098c2e09e8db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the data:\n",
            "              datetime  nat_demand    T2M_toc  QV2M_toc   TQL_toc    W2M_toc  \\\n",
            "0  2015-01-03 01:00:00    970.3450  25.865259  0.018576  0.016174  21.850546   \n",
            "1  2015-01-03 02:00:00    912.1755  25.899255  0.018653  0.016418  22.166944   \n",
            "2  2015-01-03 03:00:00    900.2688  25.937280  0.018768  0.015480  22.454911   \n",
            "3  2015-01-03 04:00:00    889.9538  25.957544  0.018890  0.016273  22.110481   \n",
            "4  2015-01-03 05:00:00    893.6865  25.973840  0.018981  0.017281  21.186089   \n",
            "\n",
            "     T2M_san  QV2M_san   TQL_san    W2M_san    T2M_dav  QV2M_dav   TQL_dav  \\\n",
            "0  23.482446  0.017272  0.001855  10.328949  22.662134  0.016562  0.096100   \n",
            "1  23.399255  0.017265  0.001327  10.681517  22.578943  0.016509  0.087646   \n",
            "2  23.343530  0.017211  0.001428  10.874924  22.531030  0.016479  0.078735   \n",
            "3  23.238794  0.017128  0.002599  10.518620  22.512231  0.016487  0.068390   \n",
            "4  23.075403  0.017059  0.001729   9.733589  22.481653  0.016456  0.064362   \n",
            "\n",
            "    W2M_dav  Holiday_ID  holiday  school  \n",
            "0  5.364148         0.0      0.0     0.0  \n",
            "1  5.572471         0.0      0.0     0.0  \n",
            "2  5.871184         0.0      0.0     0.0  \n",
            "3  5.883621         0.0      0.0     0.0  \n",
            "4  5.611724         0.0      0.0     0.0  \n",
            "\n",
            "Summary statistics:\n",
            "         nat_demand       T2M_toc      QV2M_toc       TQL_toc       W2M_toc  \\\n",
            "count  38324.000000  38324.000000  38324.000000  38324.000000  38324.000000   \n",
            "mean    1175.468350     27.369679      0.018229      0.080428     13.466975   \n",
            "std      192.914886      1.699696      0.001605      0.066482      7.348411   \n",
            "min       85.192500     22.953455      0.012054      0.000000      0.008979   \n",
            "25%     1007.749050     26.115785      0.017099      0.025999      7.551993   \n",
            "50%     1163.567700     27.087656      0.018513      0.064941     12.327402   \n",
            "75%     1322.409100     28.535875      0.019456      0.118561     18.796368   \n",
            "max     1719.043900     35.039575      0.021996      0.459839     39.229726   \n",
            "\n",
            "            T2M_san      QV2M_san       TQL_san       W2M_san       T2M_dav  \\\n",
            "count  38324.000000  38324.000000  38324.000000  38324.000000  38324.000000   \n",
            "mean      26.914304      0.017747      0.106958      7.179803     24.702605   \n",
            "std        3.063932      0.001895      0.087288      4.164689      2.443416   \n",
            "min       19.765222      0.010385      0.000009      0.060431     19.933740   \n",
            "25%       24.747514      0.016420      0.036739      4.016397     22.919077   \n",
            "50%       26.153497      0.018258      0.085419      6.161262     23.983896   \n",
            "75%       28.704233      0.019188      0.158569      9.585352     26.225412   \n",
            "max       39.063440      0.021655      0.484985     24.483937     34.216211   \n",
            "\n",
            "           QV2M_dav       TQL_dav       W2M_dav    Holiday_ID       holiday  \\\n",
            "count  38323.000000  38323.000000  38323.000000  38323.000000  38323.000000   \n",
            "mean       0.016785      0.145645      3.633573      0.713305      0.064504   \n",
            "std        0.001595      0.089338      1.740024      3.151470      0.245652   \n",
            "min        0.009655      0.000051      0.015497      0.000000      0.000000   \n",
            "25%        0.015658      0.075897      2.355049      0.000000      0.000000   \n",
            "50%        0.017084      0.129456      3.476809      0.000000      0.000000   \n",
            "75%        0.018015      0.201385      4.764576      0.000000      0.000000   \n",
            "max        0.020488      0.477783     10.288902     22.000000      1.000000   \n",
            "\n",
            "             school  \n",
            "count  38323.000000  \n",
            "mean       0.720716  \n",
            "std        0.448653  \n",
            "min        0.000000  \n",
            "25%        0.000000  \n",
            "50%        1.000000  \n",
            "75%        1.000000  \n",
            "max        1.000000  \n",
            "\n",
            "DataFrame info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 38324 entries, 0 to 38323\n",
            "Data columns (total 17 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   datetime    38324 non-null  object \n",
            " 1   nat_demand  38324 non-null  float64\n",
            " 2   T2M_toc     38324 non-null  float64\n",
            " 3   QV2M_toc    38324 non-null  float64\n",
            " 4   TQL_toc     38324 non-null  float64\n",
            " 5   W2M_toc     38324 non-null  float64\n",
            " 6   T2M_san     38324 non-null  float64\n",
            " 7   QV2M_san    38324 non-null  float64\n",
            " 8   TQL_san     38324 non-null  float64\n",
            " 9   W2M_san     38324 non-null  float64\n",
            " 10  T2M_dav     38324 non-null  float64\n",
            " 11  QV2M_dav    38323 non-null  float64\n",
            " 12  TQL_dav     38323 non-null  float64\n",
            " 13  W2M_dav     38323 non-null  float64\n",
            " 14  Holiday_ID  38323 non-null  float64\n",
            " 15  holiday     38323 non-null  float64\n",
            " 16  school      38323 non-null  float64\n",
            "dtypes: float64(16), object(1)\n",
            "memory usage: 5.0+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "file_path = '/content/continuous dataset.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "print(\"First few rows of the data:\")\n",
        "print(df.head())\n",
        "print(\"\\nSummary statistics:\")\n",
        "print(df.describe())\n",
        "print(\"\\nDataFrame info:\")\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "data = pd.read_csv('/content/continuous dataset.csv')\n",
        "\n",
        "train_data, valid_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "print(\"Training Data:\")\n",
        "print(train_data.head())\n",
        "print(\"\\nValidation Data:\")\n",
        "print(valid_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2apTcJ3TCzj",
        "outputId": "c8a696ec-6345-4f47-df25-8664762904af"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "                  datetime  nat_demand    T2M_toc  QV2M_toc   TQL_toc  \\\n",
            "39623  2019-07-12 00:00:00   1113.3099  26.576105  0.019807  0.072357   \n",
            "26601  2018-01-15 10:00:00   1397.1628  27.416406  0.017600  0.130493   \n",
            "28871  2018-04-20 00:00:00   1160.9232  27.030908  0.019511  0.052368   \n",
            "16293  2016-11-11 22:00:00   1066.5749  26.234033  0.019744  0.077423   \n",
            "12668  2016-06-13 21:00:00   1210.1754  27.437250  0.020119  0.103302   \n",
            "\n",
            "         W2M_toc    T2M_san  QV2M_san   TQL_san   W2M_san    T2M_dav  \\\n",
            "39623   7.493484  25.216730  0.019303  0.110138  4.411643  23.372980   \n",
            "26601  21.617335  26.900781  0.018088  0.187439  9.203218  23.783594   \n",
            "28871  20.961102  25.843408  0.018122  0.057312  8.439482  23.921533   \n",
            "16293   8.287791  25.304346  0.019767  0.155518  6.606283  23.171533   \n",
            "12668   6.087760  26.124750  0.020447  0.248962  5.641792  24.124750   \n",
            "\n",
            "       QV2M_dav   TQL_dav   W2M_dav  Holiday_ID  holiday  school  \n",
            "39623  0.018159  0.159668  3.881324           0        0       1  \n",
            "26601  0.017493  0.350098  0.831296           0        0       0  \n",
            "28871  0.017298  0.109039  3.230616           0        0       1  \n",
            "16293  0.018257  0.258667  5.151287           0        0       1  \n",
            "12668  0.018799  0.208923  3.334986           0        0       1  \n",
            "\n",
            "Validation Data:\n",
            "                  datetime  nat_demand    T2M_toc  QV2M_toc   TQL_toc  \\\n",
            "45068  2020-02-23 21:00:00   1124.5630  25.070886  0.015014  0.001614   \n",
            "15200  2016-09-27 09:00:00   1325.5949  27.643365  0.018823  0.177063   \n",
            "17210  2016-12-20 03:00:00    969.1594  25.381799  0.018265  0.054886   \n",
            "30002  2018-06-06 03:00:00    998.7269  26.480127  0.020472  0.093414   \n",
            "18911  2017-03-01 00:00:00    943.5333  25.713800  0.015933  0.012634   \n",
            "\n",
            "         W2M_toc    T2M_san  QV2M_san   TQL_san    W2M_san    T2M_dav  \\\n",
            "45068  22.384582  24.641199  0.014667  0.012634  12.324900  22.656824   \n",
            "15200   3.140293  28.518365  0.018373  0.141846   1.153303  24.799615   \n",
            "17210  18.067061  22.545862  0.016441  0.032028   6.459642  22.225549   \n",
            "30002   7.074711  24.839502  0.019091  0.117645   4.520269  23.097314   \n",
            "18911  23.044415  24.955988  0.016657  0.057083   9.564726  22.698175   \n",
            "\n",
            "       QV2M_dav   TQL_dav   W2M_dav  Holiday_ID  holiday  school  \n",
            "45068  0.014251  0.007761  6.410504           4        1       0  \n",
            "15200  0.017633  0.202026  1.742228           0        0       1  \n",
            "17210  0.015861  0.174316  3.545576           0        0       0  \n",
            "30002  0.018061  0.242737  4.346986           0        0       0  \n",
            "18911  0.015563  0.134521  4.022473           7        1       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "train_data = pd.read_csv(\"/content/continuous dataset.csv\")\n",
        "train_features = train_data.drop(['datetime', 'Holiday_ID'], axis=1)\n",
        "train_target = train_data['nat_demand']\n",
        "scaler = MinMaxScaler()\n",
        "train_features_normalized = scaler.fit_transform(train_features)\n",
        "print(\"Normalized Training Features:\")\n",
        "print(train_features_normalized[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEjDS2nZTKDS",
        "outputId": "7ad8dfff-fe97-458d-c958-2c969dc25dbe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Training Features:\n",
            "[[0.53013    0.24092133 0.61321834 0.03103044 0.55688809 0.19262007\n",
            "  0.58943876 0.00380735 0.42043674 0.19103092 0.6052925  0.20108292\n",
            "  0.52063079 0.         0.        ]\n",
            " [0.49529149 0.24373419 0.62044907 0.03149883 0.56495521 0.18830926\n",
            "  0.58885032 0.00271795 0.43487234 0.18520624 0.60066622 0.18338883\n",
            "  0.54090872 0.         0.        ]\n",
            " [0.4881604  0.24688035 0.63122024 0.02969848 0.57229741 0.18542169\n",
            "  0.58437987 0.00292639 0.4427912  0.18185159 0.59800289 0.16473657\n",
            "  0.569985   0.         0.        ]\n",
            " [0.48198261 0.24855696 0.64270865 0.03122073 0.56351557 0.17999443\n",
            "  0.57734883 0.00534019 0.42820267 0.18053538 0.59868259 0.14308206\n",
            "  0.57119564 0.         0.        ]\n",
            " [0.48421817 0.24990531 0.6512729  0.03315281 0.53994661 0.17152779\n",
            "  0.57154895 0.0035468  0.39606027 0.17839439 0.59596808 0.13465022\n",
            "  0.54472948 0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data (assuming both files have the same structure)\n",
        "data_path = \"/content/continuous dataset.csv\"  # Assuming same path for both files\n",
        "train_data = pd.read_csv(data_path)\n",
        "valid_data = pd.read_csv(data_path)  # Use the same path for validation data\n",
        "\n",
        "# Define features and target (assuming 'nat_demand' is the target)\n",
        "features_to_drop = ['datetime', 'Holiday_ID']\n",
        "target_variable = 'nat_demand'\n",
        "\n",
        "train_features = train_data.drop(features_to_drop, axis=1)\n",
        "train_target = train_data[target_variable]\n",
        "\n",
        "valid_features = valid_data.drop(features_to_drop, axis=1)\n",
        "valid_target = valid_data[target_variable]\n",
        "\n",
        "# Splitting data (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize features (using training data for normalization)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)  # Fit scaler only on training data\n",
        "X_train_normalized = scaler.transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)\n",
        "valid_features_normalized = scaler.transform(valid_features)  # Transform validation data using fitted scaler\n",
        "\n",
        "# Print information about splits and normalized data\n",
        "print(\"Train set shapes:\")\n",
        "print(\"  Features:\", X_train.shape, X_train_normalized.shape)\n",
        "print(\"  Target:\", y_train.shape)\n",
        "\n",
        "print(\"\\nTest set shapes:\")\n",
        "print(\"  Features:\", X_test.shape, X_test_normalized.shape)\n",
        "print(\"  Target:\", y_test.shape)\n",
        "\n",
        "print(\"\\nValidation set features shape:\", valid_features_normalized.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_w2OmeeTX9S",
        "outputId": "cfe55383-836c-4165-c06a-97d050e9c495"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shapes:\n",
            "  Features: (38438, 15) (38438, 15)\n",
            "  Target: (38438,)\n",
            "\n",
            "Test set shapes:\n",
            "  Features: (9610, 15) (9610, 15)\n",
            "  Target: (9610,)\n",
            "\n",
            "Validation set features shape: (48048, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor  # For continuous target variable\n",
        "\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=100)\n",
        "\n",
        "# Train the model on the training data\n",
        "rf.fit(X_train_normalized, y_train)\n",
        "\n",
        "# Make predictions on the testing and validation sets\n",
        "y_pred_test = rf.predict(X_test_normalized)\n",
        "y_pred_valid = rf.predict(valid_features_normalized)\n",
        "\n",
        "# Evaluation metrics (consider using appropriate metrics for regression)\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "r2_test = r2_score(y_test, y_pred_test)\n",
        "\n",
        "mse_valid = mean_squared_error(valid_target, y_pred_valid)\n",
        "r2_valid = r2_score(valid_target, y_pred_valid)\n",
        "\n",
        "print(\"\\nTest Set Performance:\")\n",
        "print(\"  Mean Squared Error:\", mse_test)\n",
        "print(\"  R-squared:\", r2_test)\n",
        "\n",
        "print(\"\\nValidation Set Performance:\")\n",
        "print(\"  Mean Squared Error:\", mse_valid)\n",
        "print(\"  R-squared:\", r2_valid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8VechfAd7Re",
        "outputId": "57e5e97a-ed17-4bcc-94eb-83e6733d944b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shapes:\n",
            "  Features: (38438, 15) (38438, 15)\n",
            "  Target: (38438,)\n",
            "\n",
            "Test set shapes:\n",
            "  Features: (9610, 15) (9610, 15)\n",
            "  Target: (9610,)\n",
            "\n",
            "Validation set features shape: (48048, 15)\n",
            "\n",
            "Test Set Performance:\n",
            "  Mean Squared Error: 1.609306841337107\n",
            "  R-squared: 0.9999563986171411\n",
            "\n",
            "Validation Set Performance:\n",
            "  Mean Squared Error: 0.733679395604485\n",
            "  R-squared: 0.9999801115343364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression  # Change to your preferred regression model\n",
        "from sklearn.metrics import mean_squared_error  # Using mean squared error for regression\n",
        "\n",
        "# ... (rest of your code for data loading and feature selection)\n",
        "\n",
        "# Train a regression model (assuming Linear Regression here)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance (using mean squared error for regression)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFQrBdScTyb6",
        "outputId": "60018524-df96-4202-dd74-b59b89cad9c4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 3.001570924589233e-26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "# Train a decision tree regression model\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance (using mean squared error for regression)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"\\nMean Squared Error:\", mse)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZPjDxrDVGyg",
        "outputId": "463dbc38-bc94-419d-84bb-26bc58491420"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape before split: (48048, 15)\n",
            "y shape before split: (48048,)\n",
            "\n",
            "X_train shape after split: (38438, 15)\n",
            "y_train shape after split: (38438,)\n",
            "\n",
            "X_test shape after split: (9610, 15)\n",
            "y_test shape after split: (9610,)\n",
            "\n",
            "Mean Squared Error: 0.8336079421304093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Impute missing values using mean imputation (replace with other strategies if needed)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Check for missing values after imputation (optional)\n",
        "print(\"\\nMissing values after imputation:\")\n",
        "print(pd.DataFrame(X_imputed).isnull().sum())  # Check for any remaining missing values\n",
        "# Evaluate model performance (using mean squared error for regression)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"\\nMean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BMgF5SSX6Sz",
        "outputId": "592c40d3-b451-44c7-c5bb-c03944e673c3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before imputation:\n",
            "nat_demand    0\n",
            "T2M_toc       0\n",
            "QV2M_toc      0\n",
            "TQL_toc       0\n",
            "W2M_toc       0\n",
            "T2M_san       0\n",
            "QV2M_san      0\n",
            "TQL_san       0\n",
            "W2M_san       0\n",
            "T2M_dav       0\n",
            "QV2M_dav      0\n",
            "TQL_dav       0\n",
            "W2M_dav       0\n",
            "holiday       0\n",
            "school        0\n",
            "dtype: int64\n",
            "\n",
            "Missing values after imputation:\n",
            "0     0\n",
            "1     0\n",
            "2     0\n",
            "3     0\n",
            "4     0\n",
            "5     0\n",
            "6     0\n",
            "7     0\n",
            "8     0\n",
            "9     0\n",
            "10    0\n",
            "11    0\n",
            "12    0\n",
            "13    0\n",
            "14    0\n",
            "dtype: int64\n",
            "\n",
            "Mean Squared Error: 2.1841628090408913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load data (assuming both files have the same structure)\n",
        "data_path = \"/content/continuous dataset.csv\"  # Assuming same path for both files\n",
        "train_data = pd.read_csv(data_path)\n",
        "valid_data = pd.read_csv(data_path)  # Use the same path for validation data\n",
        "# Create a KNN Regressor with k=5 neighbors (adjust as needed)\n",
        "knn_reg = KNeighborsRegressor(n_neighbors=5)\n",
        "# Train the model on the training data\n",
        "knn_reg.fit(X_train_normalized, y_train)\n",
        "\n",
        "# Make predictions on the testing and validation sets\n",
        "y_pred_test = knn_reg.predict(X_test_normalized)\n",
        "y_pred_valid = knn_reg.predict(valid_features_normalized)\n",
        "\n",
        "# Evaluation metrics\n",
        "mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "r2_test = r2_score(y_test, y_pred_test)\n",
        "\n",
        "mse_valid = mean_squared_error(valid_target, y_pred_valid)\n",
        "r2_valid = r2_score(valid_target, y_pred_valid)\n",
        "\n",
        "print(\"\\nTest Set Performance:\")\n",
        "print(\"  Mean Squared Error:\", mse_test)\n",
        "print(\"  R-squared:\", r2_test)\n",
        "\n",
        "print(\"\\nValidation Set Performance:\")\n",
        "print(\"  Mean Squared Error:\", mse_valid)\n",
        "print(\"  R-squared:\", r2_valid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qAC3gL-etmO",
        "outputId": "da5b082d-2f4f-4a4b-d092-4fe3ef3bef14"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shapes:\n",
            "  Features: (38438, 15) (38438, 15)\n",
            "  Target: (38438,)\n",
            "\n",
            "Test set shapes:\n",
            "  Features: (9610, 15) (9610, 15)\n",
            "  Target: (9610,)\n",
            "\n",
            "Validation set features shape: (48048, 15)\n",
            "\n",
            "Test Set Performance:\n",
            "  Mean Squared Error: 1654.4483633223676\n",
            "  R-squared: 0.9551755857512357\n",
            "\n",
            "Validation Set Performance:\n",
            "  Mean Squared Error: 1164.6149070514905\n",
            "  R-squared: 0.9684298022692408\n"
          ]
        }
      ]
    }
  ]
}